general:
  raw_data: False                    
  offline_data:           # Path to .h5 file with offline data
  model_savepath: checkpoints/       # Path to save model
  data_savepath: checkpoints/         # Path to save data
  model_save_freq: 1000
  write_data_freq: 1000
  prefill: 50000
  device: cuda
  dtype: float32
  buffer_capacity: 1000000
  enc_input_size: 64             # Change to a more unambiguous parameter name
  enc_out_size: 8
  similar: 4 
  rollout_enc_size: 16
  num_train_episodes: 2000
  max_traj_length: 1000
  imgn_length: 50
  seq_length: 50
  n_sam_eps: 32
  reset_interval: 0

atari:
  frame_size: [128, 128]
  action_repeat: 4
  grayscale: False
  noops: 30
  life_done: False
  sticky_actions: True
  all_actions: True
  time_limit: 27000
  no_terminal: False
  prefill_steps: 15000
  deter_dim: 1024
  kl_weight: 0.1
  ac_gamma: 0.99
  entropy: 0.01
  clip_rewards: 

kmeans: 
  n_clusters: 4
  init: k-means++
  n_init: 10
  max_iter: 300
  tol: 0.0001
  verbose: False
  random_state: 0
  copy_x: True
  algorithm: auto

dreamer:
  deter_dim: 2048
  stoch_dim: 32
  stoch_discrete: 32
  hidden_dim: 1000   # Does this have something to do with enc output shape?
  gru_layers: 1
  gru_type: gru
  layer_norm: True
  image_encoder: cnn
  cnn_depth: 48
  image_encoder_layers: 0
  image_decoder: cnn
  image_decoder_layers: 0
  reward_input: False
  reward_decoder_layers: 4
  reward_decoder_categorical: 
  terminal_decoder_layers: 4
  map_stoch_dim: 64
  map_model: none
  map_decoder: dense
  map_hidden_layers: 4
  map_hidden_dim: 1024
  map_channels: 4
  map_size: 11
  mem_model: none
  mem_loss_type: 

  # Actor Critic
  ac_gamma: 0.995
  lambda_gae: 0.95
  entropy: 0.003
  target_interval: 100
  imag_horizon: 15
  actor_grad: reinforce
  actor_dist: onehot

  # Training
  kl_weight: 1.0
  kl_balance: 0.8
  adam_lr: 3.0e-4
  adam_lr_actor: 1.0e-4
  adam_lr_critic: 1.0e-4
  adam_eps: 1.0e-5
  amp: True
  iwae_samples: 1
  image_weight: 1.0
  vecobs_weight: 1.0
  reward_weight: 1.0
  terminal_weight: 1.0
  image_decoder_min_prob: 0
  reset_interval: 200

dqn:
  hidden_layers: [64, 64]
  model_activation: relu
  model_dropout: 0.0
  dqn_gamma: 0.99
  dqn_epsilon: 0.1
  dqn_batch_size: 16
  dqn_tau: 0.995
  learning_rate: 0.01    #same for the agent encoder
  trg_update_freq: 2